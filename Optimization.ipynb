{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def deriv(f, x, h=0.0001):\n",
    "    return (f(x+h) - f(x-h))/(2*h)\n",
    "\n",
    "def s_deriv(f, x, h=0.0001):\n",
    "    return (f(x+h) - 2.0*f(x) + f(x-h))/(h*h)\n",
    "\n",
    "def parabolic_iteration(f, l, r, e=1.0e-20):\n",
    "    count = 0\n",
    "    u = l\n",
    "    v = (r-l)/2.0\n",
    "    w = r\n",
    "\n",
    "    while abs(u-w) > e:\n",
    "        fu = f(u)\n",
    "        fv = f(v)\n",
    "        fw = f(w)\n",
    "        p = (v - u)**2 * (fv - fw) - (v - w)**2 * (fv - fu)\n",
    "        q = (v - u) * (fv - fw) - (v - w) * (fv - fu)\n",
    "        if q == 0:\n",
    "            break\n",
    "        next = v - p/(2*q)\n",
    "        \n",
    "        u = w\n",
    "        w = v\n",
    "        v = next\n",
    "\n",
    "        count+=1\n",
    "\n",
    "    return v, count\n",
    "\n",
    "def netwon_optimization(f, l, r, e=1.0e-20):\n",
    "    count = 0\n",
    "    x = (r-l)/2.0\n",
    "    step = 1.0\n",
    "    while abs(step) > e:\n",
    "        step = deriv(f,x)/s_deriv(f, x)\n",
    "        x -= step\n",
    "        count+=1\n",
    "    return x, count\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above functions perform optimization in 1 dimension in two different ways, using Newtons method and using interpolation by a parabola and taking its minima to obtain new esimates. Lets test the number of steps needed to obtain a certain accuracy for each method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(solution, iterations)\n",
      "(1.570796326794995, 4)\n",
      "(1.5707963261525917, 7)\n",
      "(0.4999999999999998, 3)\n",
      "(0.5, 2)\n",
      "(1.2152504351316875, 5)\n",
      "(1.2152504394041972, 9)\n"
     ]
    }
   ],
   "source": [
    "def f(x):\n",
    "    return np.sin(x)\n",
    "\n",
    "def f2(x):\n",
    "    return -x*x +x\n",
    "\n",
    "def f3(x):\n",
    "    return -x*x*x + x*x + 2.0*x\n",
    "\n",
    "print('(solution, iterations)')\n",
    "print(netwon_optimization(f, 1, 4))\n",
    "print(parabolic_iteration(f, 1, 4))\n",
    "print(netwon_optimization(f2, 0, 3))\n",
    "print(parabolic_iteration(f2, 0, 3))\n",
    "print(netwon_optimization(f3, 0, 3))\n",
    "print(parabolic_iteration(f3, 0, 3))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Newtons method appears to be quicker in general, of course this comes at the cost of extra error and computation needed for computing the derivative. Both of these methods may also fail to converge in some instances, and newtons method may instead converge to an inflection point..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate some examples of failures to converge"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are methods that have guarenteed convergence but this generally comes at the cost of a slower convergence rate. Below is an example of this know as the golden section method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement golden section method"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can combine techniques to achieve guaranteed convergence while hopefully increasing the speed substantially. To do this we simply run the golden section method to some tolerence level then apply newtons method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined method"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now make this more robust so it actually verifies that the obtained point is a minima and refines or retries if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finalized method that works in a much wider range of cases\n",
    "\n",
    "# tests to demonstrate robustness of the final function"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
