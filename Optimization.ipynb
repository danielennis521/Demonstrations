{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def deriv(f, x, h=0.00001):\n",
    "    return (f(x+h) - f(x-h))/(2*h)\n",
    "\n",
    "def s_deriv(f, x, h=0.00001):\n",
    "    return (f(x+h) - 2.0*f(x) + f(x-h))/(h*h)\n",
    "\n",
    "def parabolic_iteration(f, l, r, e=1.0e-20):\n",
    "    count = 0\n",
    "    u = l\n",
    "    v = (r-l)/2.0\n",
    "    w = r\n",
    "\n",
    "    while abs(u-w) > e:\n",
    "        fu = f(u)\n",
    "        fv = f(v)\n",
    "        fw = f(w)\n",
    "        p = (v - u)**2 * (fv - fw) - (v - w)**2 * (fv - fu)\n",
    "        q = (v - u) * (fv - fw) - (v - w) * (fv - fu)\n",
    "        if q == 0:\n",
    "            break\n",
    "        next = v - p/(2*q)\n",
    "        \n",
    "        u = w\n",
    "        w = v\n",
    "        v = next\n",
    "\n",
    "        count+=1\n",
    "\n",
    "    return v, count\n",
    "\n",
    "def netwon_optimization(f, l, r, e=1.0e-20):\n",
    "    count = 0\n",
    "    x = (r-l)/2.0\n",
    "    step = 1.0\n",
    "    while abs(step) > e and count <10:\n",
    "        step = deriv(f,x)/s_deriv(f, x)\n",
    "        x -= step\n",
    "        count+=1\n",
    "    return x, count\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above functions perform optimization in 1 dimension in two different ways, using Newtons method and using interpolation by a parabola and taking its minima to obtain new esimates. Lets test the number of steps needed to obtain a certain accuracy for each method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(solution, iterations)\n",
      "(0.7071067812116412, 6)\n",
      "(0.7071067840797851, 13)\n",
      "(0.4999999999999997, 3)\n",
      "(0.5, 2)\n",
      "(1.2152504370068424, 5)\n",
      "(1.2152504394041972, 9)\n"
     ]
    }
   ],
   "source": [
    "def f(x):\n",
    "    return 0.5 - x*np.exp(-x*x)\n",
    "\n",
    "def f2(x):\n",
    "    return x*x - x\n",
    "\n",
    "def f3(x):\n",
    "    return x*x*x - x*x - 2.0*x\n",
    "\n",
    "print('(solution, iterations)')\n",
    "print(netwon_optimization(f, 0, 1))\n",
    "print(parabolic_iteration(f, 0, 1))\n",
    "print(netwon_optimization(f2, 0, 3))\n",
    "print(parabolic_iteration(f2, 0, 3))\n",
    "print(netwon_optimization(f3, 0, 3))\n",
    "print(parabolic_iteration(f3, 0, 3))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Newtons method appears to be quicker in general, of course this comes at the cost of extra error and computation needed for computing the derivative. Both of these methods may also fail to converge in some instances, and newtons method may instead converge to an inflection point or maximum..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(solution, iterations)\n",
      "(-4.4948413616347285e-12, 5)\n",
      "(-6.283185307201398, 11)\n",
      "(3.1415926536331837, 8)\n"
     ]
    }
   ],
   "source": [
    "# generate some examples of failures to converge\n",
    "print('(solution, iterations)')\n",
    "print(netwon_optimization(np.cos, 2, 4))\n",
    "print(parabolic_iteration(np.cos, 0, 3))\n",
    "print(parabolic_iteration(np.cos, 2, 4))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are methods that have guarenteed convergence but this generally comes at the cost of a slower convergence rate. Below is an example of this know as the golden section method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(left, right, iterations)\n",
      "(3.1415926430465917, 3.1415926431124714, 51)\n",
      "(0.4999999962345232, 0.4999999963004029, 51)\n",
      "(1.215250425468034, 1.2152504255339138, 51)\n"
     ]
    }
   ],
   "source": [
    "# implement golden section method\n",
    "def golden_section(f, l, r, e=1.0e-10):\n",
    "    count = 0\n",
    "    t = (np.sqrt(5) - 1.0)/2.0\n",
    "    x1 = l + (1-t)*(r-l)\n",
    "    f1 = f(x1)\n",
    "    x2 = l + t*(r-l)\n",
    "    f2 = f(x2)\n",
    "\n",
    "    while r-l > e:\n",
    "        if f1 > f2:\n",
    "            l = x1\n",
    "            x1 = x2\n",
    "            f1 = f2\n",
    "            x2 = l + t*(r-l)\n",
    "            f2 = f(x2)\n",
    "        else:\n",
    "            r = x2\n",
    "            x2 = x1\n",
    "            f2 = f1\n",
    "            x1 = l + (1-t)*(r-l)\n",
    "            f1 = f(x1)\n",
    "        count += 1\n",
    "\n",
    "    return l, r, count\n",
    "\n",
    "\n",
    "print('(left, right, iterations)')\n",
    "print(golden_section(np.cos, 1, 4))\n",
    "print(golden_section(f2, 0, 3))\n",
    "print(golden_section(f3, 0, 3))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can combine techniques to achieve guaranteed convergence while hopefully increasing the speed substantially. To do this we simply run the golden section method to some tolerence level then apply parabolic iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(solution, golden iterations, parabolic iterations)\n",
      "(3.1415926535886403, 16, 6)\n",
      "(0.5000000000000473, 17, 3)\n",
      "(1.2152504346241997, 17, 6)\n"
     ]
    }
   ],
   "source": [
    "# combined method\n",
    "def combined_optimization(f, l, r, e=1.0e-20):\n",
    "    \n",
    "    l, r, g_count = golden_section(f, l, r, 1.0e-3)\n",
    "    x, p_count = parabolic_iteration(f, l, r, e=1.0e-20)\n",
    "    return x, g_count, p_count\n",
    "\n",
    "\n",
    "print('(solution, golden iterations, parabolic iterations)')\n",
    "print(combined_optimization(np.cos, 2, 4))\n",
    "print(combined_optimization(f2, 0, 3))\n",
    "print(combined_optimization(f3, 0, 3))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are much more promising results, we obtain twice the accuracy as the golden section method in roughly half the number of steps while still benefiting from the improved convergence properties."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
